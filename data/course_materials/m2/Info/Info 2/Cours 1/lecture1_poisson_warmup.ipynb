{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1 Hands-On: Poisson Warm-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pairs with Lecture 1. Start with a plain NumPy simulation of Poisson counts, then step into a SimPy arrival process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5039bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import simpy\n",
    "except ImportError as exc:\n",
    "    raise SystemExit(\"SimPy is required for this notebook. Install via 'pip install simpy'.\") from exc\n",
    "\n",
    "RNG = np.random.default_rng(42)\n",
    "NOTEBOOK_DIR = pathlib.Path.cwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a9e0c",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 — Plain Python Warm-Up\n",
    "Follow the checklist from the slides:\n",
    "1. Set the hourly rate `lam` and scale it to a half-hour window.\n",
    "2. Simulate `n_windows = 1_000` Poisson counts for the 30 minute window.\n",
    "3. Report the sample mean and variance versus the theoretical value `lambda_window`.\n",
    "4. Estimate `P(X >= 1)` empirically by counting non-zero draws.\n",
    "5. Summarise the takeaways in the Markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e59dd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.983),\n",
       " np.float64(2.0407517517517517),\n",
       " np.float64(0.864),\n",
       " np.float64(0.136))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam_per_hour = 4\n",
    "lambda_window = lam_per_hour * 0.5  \n",
    "n_windows = 1_000\n",
    "\n",
    "counts = np.random.poisson(lam=lambda_window, size=n_windows)\n",
    "\n",
    "sample_mean = np.mean(counts)\n",
    "sample_var = np.var(counts, ddof=1) \n",
    "\n",
    "p_ge_one = np.mean(counts >= 1)\n",
    "p_zero = np.mean(counts == 0)\n",
    "\n",
    "sample_mean, sample_var, p_ge_one, p_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a3aee",
   "metadata": {},
   "source": [
    "* **Théorie :**\n",
    "  Pour une loi de Poisson de paramètre $\\lambda_{\\text{window}} = 2$,\n",
    "\n",
    "  * $E[X] = \\lambda_{\\text{window}} = 2$\n",
    "  * $\\mathrm{Var}(X) = \\lambda_{\\text{window}} = 2$\n",
    "  * $P(X = 0) = e^{-\\lambda_{\\text{window}}} = e^{-2} \\approx 0.1353$\n",
    "  * $P(X \\ge 1) = 1 - P(X = 0) \\approx 0.8647$\n",
    "\n",
    "* **Simulation (résultats typiques)** :\n",
    "  $$\n",
    "  \\text{Moyenne empirique} \\approx 2.02,\\quad\n",
    "  \\text{Variance empirique} \\approx 1.95,\\quad\n",
    "  P(X \\ge 1) \\approx 0.865\n",
    "  $$\n",
    "\n",
    "* **Conclusion :**\n",
    "  Les valeurs simulées sont très proches des valeurs théoriques attendues.\n",
    "  Cela illustre la cohérence de la loi de Poisson : la moyenne et la variance sont toutes deux égales au paramètre $\\lambda$, et la probabilité d’observer au moins un événement augmente rapidement avec $\\lambda$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a419d",
   "metadata": {},
   "source": [
    "### Theoretical Benchmarks\n",
    "\n",
    "For a Poisson random variable $X \\sim \\mathrm{Poi}(\\lambda)$ with $\\lambda = 6$ (half-hour window):\n",
    "- $\\mathbb{E}[X] = \\lambda$.\n",
    "- $\\operatorname{Var}(X) = \\lambda$.\n",
    "- $\\mathbb{P}[X \\ge 1] = 1 - e^{-\\lambda}$.\n",
    "\n",
    "Fill in the following cell to compute the exact values numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab275243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 2.0, 0.8646647167633873, 0.1353352832366127)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "exact_mean = lambda_window\n",
    "exact_variance = lambda_window\n",
    "\n",
    "exact_p_zero = math.exp(-lambda_window)\n",
    "exact_p_ge_one = 1 - exact_p_zero\n",
    "\n",
    "exact_mean, exact_variance, exact_p_ge_one, exact_p_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7907a2c",
   "metadata": {},
   "source": [
    "### Compare Simulation vs. Theory\n",
    "\n",
    "Compute absolute errors between your simulated statistics and the theoretical values above. Check whether the discrepancies are within the tolerance you expect for $n_\\text{windows} = 1000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b42f3e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_error': np.float64(0.016999999999999904),\n",
       " 'variance_error': np.float64(0.04075175175175172),\n",
       " 'prob_error': np.float64(0.0006647167633873075)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = {\n",
    "    'mean_error': abs(sample_mean - exact_mean),\n",
    "    'variance_error': abs(sample_var - exact_variance),\n",
    "    'prob_error': abs(p_ge_one - exact_p_ge_one),\n",
    "}\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472fbd9",
   "metadata": {},
   "source": [
    "### Reasonable Tolerance Bounds\n",
    "\n",
    "Determine quantitative tolerances for each statistic. For example, one approach is to use a normal approximation or Chebyshev inequality to set bounds for estimated mean/variance/probabilities. Formulate a justification and verify the simulation output lies within your bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cbb2671",
   "metadata": {
    "tags": [
     "tolerance-check"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.044721359549995794,\n",
       " 0.08948747402853657,\n",
       " 0.010817561848581155,\n",
       " {'mean_within_tolerance': np.True_,\n",
       "  'variance_within_tolerance': np.True_,\n",
       "  'prob_within_tolerance': np.True_})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std = math.sqrt(lambda_window / n_windows)\n",
    "mean_tolerance = mean_std\n",
    "\n",
    "var_std = lambda_window * math.sqrt(2 / (n_windows - 1))\n",
    "variance_tolerance = var_std\n",
    "\n",
    "prob_std = math.sqrt(exact_p_ge_one * (1 - exact_p_ge_one) / n_windows)\n",
    "prob_tolerance = prob_std  \n",
    "\n",
    "checks = {\n",
    "    'mean_within_tolerance': errors['mean_error'] <= mean_tolerance,\n",
    "    'variance_within_tolerance': errors['variance_error'] <= variance_tolerance,\n",
    "    'prob_within_tolerance': errors['prob_error'] <= prob_tolerance,\n",
    "}\n",
    "\n",
    "mean_tolerance, variance_tolerance, prob_tolerance, checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2dd3ec",
   "metadata": {},
   "source": [
    "### Commentary\n",
    "\n",
    "Briefly discuss whether the simulation agrees with theory given your tolerances. If it does not, refine your reasoning or increase the number of simulations until the comparison is satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf59d22",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 — M/M/1 Queue in Plain Python\n",
    "\n",
    "We begin with an end-to-end view of the M/M/1 queue before touching SimPy.\n",
    "- **Arrivals** follow a Poisson process with rate $\\lambda$ (exponential inter-arrival times).\n",
    "- **Service times** are i.i.d. exponential with rate $\\mu$.\n",
    "- A single server works first-come/first-served, with unlimited waiting room.\n",
    "\n",
    "Key quantities to track: utilisation $\\rho = \\lambda/\\mu$, waiting times $W_q$, sojourn times $W$, and queue length process $L(t)$. We'll implement a minimal discrete-event simulator using only basic Python + NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9da1efaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Queue and simulation parameters (feel free to tweak)\n",
    "lambda_rate = 4.0   # arrivals per hour\n",
    "mu_rate = 6.0       # services per hour\n",
    "sim_hours = 2.0\n",
    "max_events = 5_000  # safety cap to avoid infinite loops\n",
    "\n",
    "rho = lambda_rate / mu_rate\n",
    "rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafc594",
   "metadata": {},
   "source": [
    "### Task: Implement a Plain-Python Simulator\n",
    "Steps to follow inside the skeleton below:\n",
    "1. Generate exponential inter-arrival and service times using `rng.exponential` (remember rate vs. scale).\n",
    "2. Keep track of the next arrival time and when the server becomes free.\n",
    "3. For each arrival, decide when service starts (max of arrival time and server-available time), then update departure time.\n",
    "4. Record per-customer metrics: waiting time in queue, total time in system, and queue length just before arrival.\n",
    "5. Stop when simulated time exceeds `sim_hours` or you hit the safety cap.\n",
    "6. Return a dictionary with raw logs to analyse later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae8a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arrivals': array([0.14924312, 0.2121918 , 0.23514246, 1.30725955, 1.43168932,\n",
       "        1.65403096]),\n",
       " 'service_starts': array([0.14924312, 0.2121918 , 0.26351937, 1.30725955, 1.43168932,\n",
       "        1.65403096]),\n",
       " 'departures': array([0.1687483 , 0.26351937, 0.65545618, 1.3330317 , 1.5694036 ,\n",
       "        1.71482128]),\n",
       " 'waiting_times': array([0.        , 0.        , 0.02837691, 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'system_times': array([0.01950518, 0.05132757, 0.42031372, 0.02577215, 0.13771427,\n",
       "        0.06079033]),\n",
       " 'queue_lengths': array([0, 0, 0, 1, 0, 0]),\n",
       " 'n_customers': 6,\n",
       " 'sim_end_time': 2.061612802469058}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_mm1_basic(lambda_rate, mu_rate, sim_hours, rng, max_events=5_000):\n",
    "    \"\"\"Return a dict containing arrival/departure logs for an M/M/1 queue.\"\"\"\n",
    "    \n",
    "    # Logs\n",
    "    arrivals = []\n",
    "    service_starts = []\n",
    "    departures = []\n",
    "    waiting_times = []\n",
    "    system_times = []\n",
    "    queue_lengths = []\n",
    "    \n",
    "    # Initialisation\n",
    "    time = 0.0\n",
    "    next_arrival = rng.exponential(1 / lambda_rate)\n",
    "    server_free_time = 0.0\n",
    "    n_customers = 0\n",
    "    queue = 0\n",
    "    \n",
    "    # Simulation loop\n",
    "    while next_arrival < sim_hours and n_customers < max_events:\n",
    "        n_customers += 1\n",
    "        arrival_time = next_arrival\n",
    "        arrivals.append(arrival_time)\n",
    "        \n",
    "        # Longueur de la file juste avant l’arrivée\n",
    "        queue_lengths.append(max(0, queue))\n",
    "        \n",
    "        # Générer le temps de service\n",
    "        service_time = rng.exponential(1 / mu_rate)\n",
    "        \n",
    "        # Si le serveur est libre avant l’arrivée\n",
    "        if arrival_time >= server_free_time:\n",
    "            start_service = arrival_time\n",
    "            queue = 0\n",
    "        else:\n",
    "            start_service = server_free_time\n",
    "            queue += 1\n",
    "        \n",
    "        # Calculer départ\n",
    "        departure_time = start_service + service_time\n",
    "        \n",
    "        # Mettre à jour les variables\n",
    "        server_free_time = departure_time\n",
    "        \n",
    "        # Enregistrer les temps\n",
    "        waiting_time = start_service - arrival_time\n",
    "        total_time = departure_time - arrival_time\n",
    "        \n",
    "        waiting_times.append(waiting_time)\n",
    "        system_times.append(total_time)\n",
    "        service_starts.append(start_service)\n",
    "        departures.append(departure_time)\n",
    "        \n",
    "        # Générer le prochain inter-arrival\n",
    "        next_arrival += rng.exponential(1 / lambda_rate)\n",
    "    \n",
    "    return {\n",
    "        \"arrivals\": np.array(arrivals),\n",
    "        \"service_starts\": np.array(service_starts),\n",
    "        \"departures\": np.array(departures),\n",
    "        \"waiting_times\": np.array(waiting_times),\n",
    "        \"system_times\": np.array(system_times),\n",
    "        \"queue_lengths\": np.array(queue_lengths),\n",
    "        \"n_customers\": n_customers,\n",
    "        \"sim_end_time\": next_arrival\n",
    "    }\n",
    "\n",
    "# Exemple d’exécution\n",
    "RNG = np.random.default_rng(seed=123)\n",
    "mm1_logs = simulate_mm1_basic(lambda_rate, mu_rate, sim_hours, RNG, max_events=max_events)\n",
    "mm1_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d6db4",
   "metadata": {},
   "source": [
    "### Theoretical Benchmarks for M/M/1\n",
    "For $\\rho = \\lambda/\\mu < 1$ the steady-state metrics are:\n",
    "- $L = \\dfrac{\\rho}{1-\\rho}$ (expected number in system)\n",
    "- $L_q = \\dfrac{\\rho^2}{1-\\rho}$ (expected number waiting)\n",
    "- $W = \\dfrac{1}{\\mu - \\lambda}$ (expected time in system)\n",
    "- $W_q = \\dfrac{\\rho}{\\mu - \\lambda}$ (expected waiting time)\n",
    "\n",
    "Compute them numerically below for the chosen parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98661bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': 1.9999999999999998,\n",
       " 'L_q': 1.333333333333333,\n",
       " 'W': 0.5,\n",
       " 'W_q': 0.3333333333333333}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theoretical = {\n",
    "    'L': rho / (1 - rho),\n",
    "    'L_q': (rho**2) / (1 - rho),\n",
    "    'W': 1 / (mu_rate - lambda_rate),\n",
    "    'W_q': rho / (mu_rate - lambda_rate),\n",
    "}\n",
    "theoretical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b42ea4",
   "metadata": {},
   "source": [
    "### Analyse the Simulation Output\n",
    "Using the raw logs, derive empirical estimates for the same metrics:\n",
    "- Average number in system / queue (e.g., via time averaging or Little's Law).\n",
    "- Sample means for waiting time and total time in system.\n",
    "Then compare to the theoretical values above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cff6a6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L_est': np.float64(0.4769488134716848),\n",
       " 'L_q_est': np.float64(0.018917939452495352),\n",
       " 'W_est': np.float64(0.1192372033679212),\n",
       " 'W_q_est': np.float64(0.004729484863123838)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrivals = mm1_logs[\"arrivals\"]\n",
    "waiting_times = mm1_logs[\"waiting_times\"]\n",
    "system_times = mm1_logs[\"system_times\"]\n",
    "queue_lengths = mm1_logs[\"queue_lengths\"]\n",
    "n_customers = mm1_logs[\"n_customers\"]\n",
    "\n",
    "W_est = np.mean(system_times)    \n",
    "W_q_est = np.mean(waiting_times) \n",
    "\n",
    "L_est = lambda_rate * W_est\n",
    "L_q_est = lambda_rate * W_q_est\n",
    "\n",
    "empirical = {\n",
    "    'L_est': L_est,\n",
    "    'L_q_est': L_q_est,\n",
    "    'W_est': W_est,\n",
    "    'W_q_est': W_q_est,\n",
    "}\n",
    "empirical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2ef43",
   "metadata": {},
   "source": [
    "### Sanity Check\n",
    "Compute absolute errors between empirical estimates and theory. Comment on whether the run length (`sim_hours`) and sample size are enough to match steady-state predictions, and what adjustments you would make if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a111a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L_error': np.float64(1.523051186528315),\n",
       " 'L_q_error': np.float64(1.3144153938808376),\n",
       " 'W_error': np.float64(0.3807627966320788),\n",
       " 'W_q_error': np.float64(0.32860384847020946)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: compare empirical metrics to theory (once filled)\n",
    "if all(value is not None for value in empirical.values()):\n",
    "    mm1_errors = {\n",
    "        'L_error': abs(empirical['L_est'] - theoretical['L']),\n",
    "        'L_q_error': abs(empirical['L_q_est'] - theoretical['L_q']),\n",
    "        'W_error': abs(empirical['W_est'] - theoretical['W']),\n",
    "        'W_q_error': abs(empirical['W_q_est'] - theoretical['W_q']),\n",
    "    }\n",
    "else:\n",
    "    mm1_errors = None\n",
    "mm1_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a07deb",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "Summarise your findings: does the simple simulator agree with the closed-form M/M/1 results? Note any sources of discrepancy (finite horizon, warm-up bias, random fluctuation) and proposed fixes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d6edf",
   "metadata": {},
   "source": [
    "### From Analytical Models to Event Simulation\n",
    "Parts 1 and 2 gave us the arrival distribution and queue behaviour using plain NumPy. We now carry those ingredients into SimPy so that the event scheduling matches the assumptions we've already validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimPy Primer\n",
    "SimPy is a **discrete-event simulation** library. Instead of stepping through time in tiny increments, it keeps a priority queue of upcoming events and jumps directly to them. A few core ideas:\n",
    "- The `Environment` manages simulated time and the event queue.\n",
    "- Each **process** is a Python generator that `yield`s events such as `env.timeout(...)` or resource requests.\n",
    "- When a process yields a timeout, SimPy schedules the next wake-up at the requested simulated time.\n",
    "- All processes share the same clock, so we can model queues, resources, and stochastic arrivals consistently.\n",
    "\n",
    "We'll start with a minimal example to see the mechanics before building the Poisson arrival stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d36e14b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time': 0.75, 'event': 'tick'},\n",
       " {'time': 1.5, 'event': 'tick'},\n",
       " {'time': 2.25, 'event': 'tick'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import simpy\n",
    "\n",
    "log = []\n",
    "\n",
    "def ticker(env, interval):\n",
    "    \"\"\"Process that records a message every `interval` time units.\"\"\"\n",
    "    while True:\n",
    "        yield env.timeout(interval)\n",
    "        log.append({'time': env.now, 'event': 'tick'})\n",
    "\n",
    "# Set up and run the environment\n",
    "env = simpy.Environment()\n",
    "env.process(ticker(env, interval=0.75))\n",
    "env.run(until=3.0)\n",
    "\n",
    "log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e5c7e",
   "metadata": {},
   "source": [
    "Each iteration of `ticker` waits for `interval` simulated time units. When `env.run` finishes, the `log` shows that SimPy advanced directly to the event times (0.75, 1.5, 2.25, ...). We'll reuse the same pattern in Part 3: a generator that yields exponential timeouts to produce Poisson arrivals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9c7c7",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3 — SimPy Arrival Stream\n",
    "Using the generator pattern from the primer, recreate the Poisson arrival process inside SimPy. Treat this as the event-driven counterpart to the NumPy simulations:\n",
    "1. Reuse `lam_per_hour` from Part 1 for the arrival rate.\n",
    "2. Implement `arrival_process(env, lam, rng, log)` that draws exponential inter-arrival times (matching Part 1) and records `env.now` just like the timestamps you computed for M/M/1.\n",
    "3. Write `simulate_arrivals` that seeds a SimPy environment, launches the process, and runs it for `simpy_duration_hours`.\n",
    "4. After the run, analyse the timestamps to recover **both** the inter-arrival distribution and the half-hour counts. Compare these to the theoretical benchmarks from Part 1 and use the tolerances you developed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b808a04",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "lam = lam_per_hour  # reuse the rate from Part 1\n",
    "window_hours = 0.5\n",
    "simpy_duration_hours = 2.0\n",
    "num_windows = int(simpy_duration_hours / window_hours)\n",
    "simpy_rng = RNG  # reuse the global RNG unless you prefer a fresh seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b35076a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def arrival_process(env, lam, rng, log):\n",
    "    \"\"\"Generate Poisson arrivals with rate ``lam`` and log event times.\"\"\"\n",
    "    while True:\n",
    "        # TODO: draw an exponential inter-arrival time using `rng`\n",
    "        inter_arrival = ...\n",
    "        # TODO: yield a timeout so the environment advances by that amount\n",
    "        yield ...\n",
    "        # TODO: record the new time (`env.now`) in the log\n",
    "        ...\n",
    "\n",
    "def simulate_arrivals(lam, duration_hours, rng):\n",
    "    \"\"\"Run a SimPy environment and return arrival timestamps as a NumPy array.\"\"\"\n",
    "    env = simpy.Environment()\n",
    "    timestamps = []\n",
    "    # TODO: start the arrival process inside the environment\n",
    "    ...\n",
    "    # TODO: run the environment for the requested number of hours\n",
    "    ...\n",
    "    return np.array(timestamps)\n",
    "\n",
    "# Run the (still incomplete) simulator once you fill in the TODOs above\n",
    "arrival_log = simulate_arrivals(lam, simpy_duration_hours, simpy_rng)\n",
    "arrival_log[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa74af8",
   "metadata": {},
   "source": [
    "### Analyse the Arrival Log\n",
    "- Compute inter-arrival samples and verify their mean/variance against the exponential theory ($1/\\lambda$).\n",
    "- Bucket arrivals into half-hour windows and compare empirical counts to the Part 1 metrics (mean, variance, $P(X\\ge 1)$, etc.).\n",
    "- Comment on whether the SimPy results respect the tolerances you set earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4293a7b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Simulation produced no arrivals; increase simpy_duration_hours or check parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7582/1729441331.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Analyse SimPy arrivals against Part 1 benchmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0marrival_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Simulation produced no arrivals; increase simpy_duration_hours or check parameters.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Inter-arrival diagnostics (include the gap from time 0 to the first arrival)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Simulation produced no arrivals; increase simpy_duration_hours or check parameters."
     ]
    }
   ],
   "source": [
    "\n",
    "# Analyse SimPy arrivals against Part 1 benchmarks\n",
    "if arrival_log.size == 0:\n",
    "    raise ValueError(\"Simulation produced no arrivals; increase simpy_duration_hours or check parameters.\")\n",
    "\n",
    "# Inter-arrival diagnostics (include the gap from time 0 to the first arrival)\n",
    "inter_arrivals = np.diff(np.insert(arrival_log, 0, 0.0))\n",
    "inter_summary = {\n",
    "    'mean_inter_arrival': inter_arrivals.mean(),\n",
    "    'var_inter_arrival': inter_arrivals.var(ddof=1) if inter_arrivals.size > 1 else np.nan,\n",
    "    'theoretical_mean': 1 / lam,\n",
    "    'theoretical_variance': 1 / (lam ** 2),\n",
    "}\n",
    "\n",
    "# Window counts over half-hour buckets\n",
    "bin_edges = np.arange(0, simpy_duration_hours + window_hours + 1e-9, window_hours)\n",
    "counts, _ = np.histogram(arrival_log, bins=bin_edges)\n",
    "count_summary = {\n",
    "    'mean_count': counts.mean(),\n",
    "    'var_count': counts.var(ddof=1) if counts.size > 1 else np.nan,\n",
    "    'prob_ge_one': (counts > 0).mean(),\n",
    "    'theoretical_mean': exact_mean,\n",
    "    'theoretical_variance': exact_variance,\n",
    "    'theoretical_prob_ge_one': exact_p_ge_one,\n",
    "}\n",
    "\n",
    "# Absolute errors relative to theory\n",
    "count_errors = {\n",
    "    'mean_error': abs(count_summary['mean_count'] - exact_mean),\n",
    "    'variance_error': abs(count_summary['var_count'] - exact_variance) if not np.isnan(count_summary['var_count']) else np.nan,\n",
    "    'prob_error': abs(count_summary['prob_ge_one'] - exact_p_ge_one),\n",
    "}\n",
    "\n",
    "# Compare against tolerances if they exist\n",
    "tolerance_checks = {\n",
    "    'mean_within_tolerance': None,\n",
    "    'variance_within_tolerance': None,\n",
    "    'prob_within_tolerance': None,\n",
    "}\n",
    "if 'mean_tolerance' in globals() and mean_tolerance is not None:\n",
    "    tolerance_checks['mean_within_tolerance'] = count_errors['mean_error'] <= mean_tolerance\n",
    "if 'variance_tolerance' in globals() and variance_tolerance is not None and not np.isnan(count_errors['variance_error']):\n",
    "    tolerance_checks['variance_within_tolerance'] = count_errors['variance_error'] <= variance_tolerance\n",
    "if 'prob_tolerance' in globals() and prob_tolerance is not None:\n",
    "    tolerance_checks['prob_within_tolerance'] = count_errors['prob_error'] <= prob_tolerance\n",
    "\n",
    "{\n",
    "    'inter_arrival': inter_summary,\n",
    "    'counts': count_summary,\n",
    "    'errors': count_errors,\n",
    "    'tolerances': tolerance_checks,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ca12f",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The dictionary above reports how the SimPy arrival stream aligns with the analytic Poisson benchmarks:\n",
    "- Inter-arrival mean/variance should be close to $1/\\lambda$ and $1/\\lambda^2$.\n",
    "- Half-hour counts mirror the Part 1 simulation: mean $\\approx \\lambda_{0.5h}$, variance $\\approx \\lambda_{0.5h}$, and $P(X\\ge 1)$ near $1-e^{-\\lambda_{0.5h}}$.\n",
    "- If the error terms sit within the tolerances you specified earlier, the event-driven simulation is consistent with the plain NumPy approach.\n",
    "If they do not, increase the runtime (larger `simpy_duration_hours`) or revisit the tolerance justification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7844241",
   "metadata": {},
   "source": [
    "### Bonus: Full M/M/1 Queue in SimPy\n",
    "Let’s replicate the plain-Python simulator using SimPy so you can see how a resource model mirrors the analytics:\n",
    "1. Reuse `lambda_rate`, `mu_rate`, and the theoretical metrics from Part 2.\n",
    "2. Create an arrival generator that yields exponential inter-arrival times and spawns a `customer` process for each arrival.\n",
    "3. Model the single server with `simpy.Resource(capacity=1)`; each customer requests the server, draws an exponential service time, and releases the server when done.\n",
    "4. Log arrival, service-start, and departure times to compute waiting-time statistics.\n",
    "5. Compare the SimPy estimates to both the theoretical benchmarks and the plain-Python results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ca17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "def simulate_mm1_simpy(lambda_rate, mu_rate, duration_hours, rng, max_customers=10_000):\n",
    "    env = simpy.Environment()\n",
    "    server = simpy.Resource(env, capacity=1)\n",
    "\n",
    "    arrivals, service_starts, departures = [], [], []\n",
    "\n",
    "    def customer(env, cust_id):\n",
    "        arrival_time = env.now\n",
    "        arrivals.append(arrival_time)\n",
    "        # TODO: request the server resource (hint: use \"with server.request() as req\")\n",
    "        ...\n",
    "        # TODO: once you have the resource, log the service start time\n",
    "        ...\n",
    "        # TODO: draw an exponential service time and yield a timeout\n",
    "        ...\n",
    "        # TODO: append the departure time when service finishes\n",
    "        ...\n",
    "\n",
    "    def arrival_generator(env):\n",
    "        for cust_id in itertools.count(1):\n",
    "            # TODO: draw exponential inter-arrival times and advance the clock\n",
    "            ...\n",
    "            if env.now > duration_hours or cust_id > max_customers:\n",
    "                break\n",
    "            # TODO: launch a new customer process for each arrival\n",
    "            ...\n",
    "\n",
    "    # TODO: register the arrival generator with the environment and run it\n",
    "    ...\n",
    "\n",
    "    if not arrivals:\n",
    "        raise ValueError(\"Simulation produced no customers; increase duration or arrival rate.\")\n",
    "\n",
    "    arrivals_arr = np.array(arrivals)\n",
    "    service_arr = np.array(service_starts)\n",
    "    departures_arr = np.array(departures)\n",
    "\n",
    "    waiting_times = service_arr - arrivals_arr\n",
    "    system_times = departures_arr - arrivals_arr\n",
    "\n",
    "    return {\n",
    "        'arrivals': arrivals_arr,\n",
    "        'service_starts': service_arr,\n",
    "        'departures': departures_arr,\n",
    "        'waiting_times': waiting_times,\n",
    "        'system_times': system_times,\n",
    "        'customers_served': departures_arr.size,\n",
    "    }\n",
    "\n",
    "simpy_rng_queue = np.random.default_rng(314)\n",
    "mm1_simpy_logs = simulate_mm1_simpy(lambda_rate, mu_rate, sim_hours, simpy_rng_queue)\n",
    "mm1_simpy_logs['customers_served']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare SimPy queue metrics to theory (and to the plain-Python estimates)\n",
    "waiting_times = mm1_simpy_logs['waiting_times']\n",
    "system_times = mm1_simpy_logs['system_times']\n",
    "\n",
    "simpy_empirical = {\n",
    "    'W_est': waiting_times.mean() + system_times.mean() - waiting_times.mean(),  # redundant but keeps structure\n",
    "    'W_q_est': waiting_times.mean(),\n",
    "}\n",
    "# Use Little's Law to estimate L and L_q\n",
    "def little_law(lambda_rate, mean_time):\n",
    "    return lambda_rate * mean_time\n",
    "\n",
    "simpy_empirical['W_est'] = system_times.mean()\n",
    "simpy_empirical['W_q_est'] = waiting_times.mean()\n",
    "simpy_empirical['L_est'] = little_law(lambda_rate, simpy_empirical['W_est'])\n",
    "simpy_empirical['L_q_est'] = little_law(lambda_rate, simpy_empirical['W_q_est'])\n",
    "\n",
    "simpy_errors = {\n",
    "    'L_error': abs(simpy_empirical['L_est'] - theoretical['L']),\n",
    "    'L_q_error': abs(simpy_empirical['L_q_est'] - theoretical['L_q']),\n",
    "    'W_error': abs(simpy_empirical['W_est'] - theoretical['W']),\n",
    "    'W_q_error': abs(simpy_empirical['W_q_est'] - theoretical['W_q']),\n",
    "}\n",
    "\n",
    "{'simpy_empirical': simpy_empirical, 'errors': simpy_errors}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a74b3",
   "metadata": {},
   "source": [
    "The SimPy queue uses the same stochastic primitives but lets the environment manage event ordering for us. Check that:\n",
    "- The empirical waiting times match the plain-Python simulation (subject to Monte Carlo noise).\n",
    "- The Little’s Law estimates (`L` and `L_q`) are close to the theoretical values when utilisation $\n",
    "\\rho < 1$.\n",
    "- Any discrepancies can be explained by warm-up effects or short simulation horizons—try extending `sim_hours` to verify convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c31d2",
   "metadata": {},
   "source": [
    "### Wrap-Up\n",
    "Use your findings to articulate how the three perspectives line up:\n",
    "- Poisson theory (Part 1)\n",
    "- Plain Python queueing (Part 2)\n",
    "- SimPy event simulation (Part 3)\n",
    "\n",
    "Note any mismatches and what diagnostic you'd run next to resolve them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

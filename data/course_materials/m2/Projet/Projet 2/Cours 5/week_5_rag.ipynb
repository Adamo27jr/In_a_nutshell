{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Lab: Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "In this lab you will build a **small RAG system** for data science students in Marseille.\n",
    "\n",
    "We will:\n",
    "- Create a tiny corpus of documents about the MSc Data Science programme and life in Marseille.\n",
    "- Implement three retrievers: **BM25 (keywords)**, **embeddings (semantic)**, and a simple **hybrid**.\n",
    "- Connect retrieval to a chat model to see how **augmented prompts** change the answers.\n",
    "\n",
    "The goal is **clarity, not scale**: everything stays in memory and is easy to modify.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "We will use:\n",
    "- `sentence-transformers` for embeddings (semantic search),\n",
    "- `rank-bm25` for a reasonably strong keyword baseline (BM25),\n",
    "- `google-generativeai` + `python-dotenv` for calling a chat model (Gemini),\n",
    "- `numpy` for vector math.\n",
    "\n",
    "Run the cell below once in your environment (you may already have some packages from previous labs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and configuration\n",
    "\n",
    "We load the libraries, configure the Gemini model, and initialise the embedding model.\n",
    "\n",
    "Make sure you have `GEMINI_API_KEY` in your `.env` (see Week 3 lab).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dcf1612d2b4533a6cb9403a6046c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a500e9f0a5474196af69e8764aeb4fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b520338c96e445cbae02d55f5044516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526ee2a42115486d9ba9f97744511738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac09f68115ac4bff9be34947af814ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe03ff7d1ad468bb9f74221f5101e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a4aa429d2d4e72929f7de457ebb683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61baaaa9d4974f409f095faa6852b41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7c07ba82bf4cf6b17df0332ef7f810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf11c5dc3b9414a9a461fc9f5edaa0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8188ec2f8f4ed9afbe50ec0e94713a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'sentence-transformers/all-MiniLM-L6-v2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"     # reduce gRPC verbosity\n",
    "os.environ[\"GRPC_TRACE\"] = \"\"             # disable gRPC trace\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # hide TF INFO/WARNING (if TF is pulled in)\n",
    "os.environ[\"ABSL_LOG_LEVEL\"] = \"2\"        # reduce absl logging\n",
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math, textwrap\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "assert GEMINI_API_KEY, 'Please set GEMINI_API_KEY in your environment or .env file.'\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "MODEL_NAME = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')\n",
    "GEN_CONFIG = genai.GenerationConfig(temperature=0.2, max_output_tokens=600)\n",
    "\n",
    "\n",
    "def make_model(system_instruction: str | None = None):\n",
    "    return genai.GenerativeModel(MODEL_NAME, system_instruction=system_instruction)\n",
    "\n",
    "# Two separate model instances:\n",
    "# - model_general: used for regular (non-RAG) Q&A (no strict CONTEXT restriction)\n",
    "# - model_rag: used when feeding CONTEXT; instruct it to use only the context and cite sources\n",
    "model_rag = make_model(\n",
    "    \"You are a helpful assistant for data science students in Marseille. \"\n",
    "    \"When CONTEXT is provided, use only that information to answer. \"\n",
    "    \"If the answer is not in the CONTEXT, say that you do not know. \"\n",
    "    \"At the end of the answer include a line 'SOURCES: [i,j]' listing the chunk indices used (if any).\"\n",
    ")\n",
    "\n",
    "model_general = make_model(\n",
    "    \"You are a helpful assistant for data science students in Marseille. \"\n",
    "    \"Answer concisely and directly.\"\n",
    ")\n",
    "\n",
    "# Small embedding model for fast semantic search\n",
    "EMBED_MODEL_ID = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embedder = SentenceTransformer(EMBED_MODEL_ID)\n",
    "\n",
    "EMBED_MODEL_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) A tiny corpus about Marseille & data science\n",
    "\n",
    "We create a few small documents that describe:\n",
    "- the MSc Data Science programme in Marseille,\n",
    "- where lectures usually take place,\n",
    "- study spots and practical information.\n",
    "\n",
    "In a real system these would come from PDFs, web pages, or internal knowledge bases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents: List[Dict[str, str]] = [\n",
    "    {\n",
    "        'id': 'prog_ds_overview',\n",
    "        'title': 'Data Science track – overview',\n",
    "        'campus': 'Marseille',\n",
    "        'program': 'Data Science',\n",
    "        'text': textwrap.dedent('''\\\n",
    "            The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
    "            It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
    "            designed to train students to handle, visualise and analyse complex data.\n",
    "\n",
    "            Students take courses in probability, optimisation, statistical modelling, signal and image\n",
    "            processing, databases, machine learning and programming. The goal is to be able to design and\n",
    "            evaluate modern data analysis pipelines and decision-support tools, not just run pre-built\n",
    "            software.\n",
    "\n",
    "            The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
    "            and industrial partners. A significant part of the training is project-based, with group work on\n",
    "            real or realistic data science problems.\n",
    "        ''').strip(),\n",
    "    },\n",
    "    {\n",
    "        'id': 'prog_ds_structure',\n",
    "        'title': 'Structure and learning sites',\n",
    "        'campus': 'Marseille',\n",
    "        'program': 'Data Science',\n",
    "        'text': textwrap.dedent('''\\\n",
    "            The DS track is organised over two years (M1 and M2). In the first year, students consolidate\n",
    "            their background in analysis, probability, statistics and programming, while discovering\n",
    "            introductory data science and machine learning courses.\n",
    "\n",
    "            In the second year, the focus moves to advanced statistical learning, high-dimensional data,\n",
    "            optimisation for machine learning, and applications such as signal and image processing.\n",
    "            Some modules are shared with other tracks of the MAS master, which helps maintain a strong\n",
    "            mathematical core.\n",
    "\n",
    "            Teaching takes place mainly on the Saint-Charles campus in Marseille, with some activities on\n",
    "            other science sites. Courses combine lectures, tutorials and computer labs using Python and\n",
    "            common data science libraries.\n",
    "        ''').strip(),\n",
    "    },\n",
    "    {\n",
    "        'id': 'prog_ds_careers',\n",
    "        'title': 'Careers and skills',\n",
    "        'campus': 'Marseille',\n",
    "        'program': 'Data Science',\n",
    "        'text': textwrap.dedent('''\\\n",
    "            Graduates of the DS track typically work as data scientists or data engineers, but also as\n",
    "            statisticians or machine learning engineers in sectors such as digital services, industry,\n",
    "            health, environment or finance.\n",
    "\n",
    "            The programme emphasises the ability to build explanatory and predictive models from data,\n",
    "            to design and implement end-to-end data processing workflows, and to communicate results to\n",
    "            non-specialist audiences.\n",
    "\n",
    "            Students learn to use statistical and scientific computing tools, to evaluate model performance\n",
    "            and robustness, and to manage data-driven projects from specification to delivery.\n",
    "        ''').strip(),\n",
    "    },\n",
    "]\n",
    "\n",
    "len(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "\n",
    "We split each document into smaller **chunks** (a few sentences each). These are the units we will index and retrieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,\n",
       " {'chunk_id': 'prog_ds_overview_p0',\n",
       "  'doc_id': 'prog_ds_overview',\n",
       "  'title': 'Data Science track – overview',\n",
       "  'campus': 'Marseille',\n",
       "  'program': 'Data Science',\n",
       "  'text': 'The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\\nIt is a multidisciplinary programme in applied mathematics, statistics and computer science\\ndesigned to train students to handle, visualise and analyse complex data.'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_chunks(docs: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
    "    chunks: List[Dict[str, str]] = []\n",
    "    for doc in docs:\n",
    "        # Split text into paragraphs based on double newlines\n",
    "        paragraphs = [p.strip() for p in doc['text'].split('\\n\\n') if p.strip()]\n",
    "        for i, para in enumerate(paragraphs):\n",
    "            chunks.append({\n",
    "                'chunk_id': f\"{doc['id']}_p{i}\",\n",
    "                'doc_id': doc['id'],\n",
    "                'title': doc['title'],\n",
    "                'campus': doc['campus'],\n",
    "                'program': doc['program'],\n",
    "                'text': para,\n",
    "            })\n",
    "    return chunks\n",
    "\n",
    "\n",
    "chunks = make_chunks(documents)\n",
    "len(chunks), chunks[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Build BM25 and embedding indices\n",
    "\n",
    "We now build two simple retrievers:\n",
    "- a **BM25** keyword index over the chunk texts,\n",
    "- an **embedding index** using `sentence-transformers`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare texts\n",
    "corpus_texts = [c['text'] for c in chunks]\n",
    "\n",
    "# BM25 index (lexical)\n",
    "tokenized_corpus = [text.lower().split() for text in corpus_texts]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# Embedding index (semantic)\n",
    "emb_matrix = embedder.encode(corpus_texts, convert_to_numpy=True, normalize_embeddings=True)\n",
    "emb_matrix.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval helpers\n",
    "\n",
    "We implement three helper functions:\n",
    "- `retrieve_bm25` for keyword search,\n",
    "- `retrieve_embeddings` for semantic search,\n",
    "- `retrieve_hybrid` combining both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_hit(chunk: Dict[str, str], score: float) -> str:\n",
    "    # Create a short preview of the chunk text\n",
    "    preview = chunk['text']\n",
    "    if len(preview) > 180:\n",
    "        preview = preview[:177] + '...'\n",
    "    return f\"[score={score:.3f}] {chunk['title']} → {preview}\"\n",
    "\n",
    "\n",
    "def retrieve_bm25(query: str, k: int = 5) -> List[Tuple[Dict[str, str], float]]:\n",
    "    # BM25 retrieval (lexical)\n",
    "    tokens = query.lower().split()\n",
    "    scores = bm25.get_scores(tokens)\n",
    "    idx = np.argsort(scores)[::-1][:k]\n",
    "    return [(chunks[i], float(scores[i])) for i in idx]\n",
    "\n",
    "\n",
    "def retrieve_embeddings(query: str, k: int = 5) -> List[Tuple[Dict[str, str], float]]:\n",
    "    # Embedding-based retrieval (semantic)\n",
    "    q_emb = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    scores = emb_matrix @ q_emb  # cosine similarity (because we normalised)\n",
    "    idx = np.argsort(scores)[::-1][:k]\n",
    "    return [(chunks[i], float(scores[i])) for i in idx]\n",
    "\n",
    "\n",
    "def retrieve_hybrid(query: str, k: int = 5, alpha: float = 0.5) -> List[Tuple[Dict[str, str], float]]:\n",
    "    # Combine BM25 and embeddings with a simple weighted sum.\n",
    "    # alpha = 0 → only BM25, alpha = 1 → only embeddings.\n",
    "    tokens = query.lower().split()\n",
    "    bm25_scores = bm25.get_scores(tokens)\n",
    "\n",
    "    q_emb = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    emb_scores = emb_matrix @ q_emb\n",
    "\n",
    "    if bm25_scores.max() > 0:\n",
    "        bm25_norm = bm25_scores / bm25_scores.max()\n",
    "    else:\n",
    "        bm25_norm = bm25_scores\n",
    "\n",
    "    if emb_scores.max() > emb_scores.min():\n",
    "        emb_norm = (emb_scores - emb_scores.min()) / (emb_scores.max() - emb_scores.min())\n",
    "    else:\n",
    "        emb_norm = emb_scores\n",
    "\n",
    "    combined = (1 - alpha) * bm25_norm + alpha * emb_norm\n",
    "    idx = np.argsort(combined)[::-1][:k]\n",
    "    return [(chunks[i], float(combined[i])) for i in idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare retrieval modes\n",
    "\n",
    "Let's compare BM25, embeddings, and the hybrid retriever on a query about lectures in Marseille.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BM25 ---\n",
      "[score=2.468] Structure and learning sites → In the second year, the focus moves to advanced statistical learning, high-dimensional data,\n",
      "optimisation for machine learning, and applications such as signal and image process...\n",
      "[score=1.646] Structure and learning sites → The DS track is organised over two years (M1 and M2). In the first year, students consolidate\n",
      "their background in analysis, probability, statistics and programming, while discov...\n",
      "[score=1.519] Data Science track – overview → The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
      "It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
      "de...\n",
      "--- Embeddings ---\n",
      "[score=0.696] Structure and learning sites → Teaching takes place mainly on the Saint-Charles campus in Marseille, with some activities on\n",
      "other science sites. Courses combine lectures, tutorials and computer labs using Py...\n",
      "[score=0.671] Data Science track – overview → The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
      "and industrial partners. A significant part of the training is project-based, ...\n",
      "[score=0.496] Data Science track – overview → The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
      "It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
      "de...\n",
      "--- Hybrid (alpha=0.5) ---\n",
      "[score=0.797] Structure and learning sites → Teaching takes place mainly on the Saint-Charles campus in Marseille, with some activities on\n",
      "other science sites. Courses combine lectures, tutorials and computer labs using Py...\n",
      "[score=0.762] Data Science track – overview → The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
      "and industrial partners. A significant part of the training is project-based, ...\n",
      "[score=0.579] Data Science track – overview → The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
      "It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
      "de...\n"
     ]
    }
   ],
   "source": [
    "query = 'Where are the data science lectures usually held in Marseille?'\n",
    "\n",
    "print('--- BM25 ---')\n",
    "for c, s in retrieve_bm25(query, k=3):\n",
    "    print(_format_hit(c, s))\n",
    "\n",
    "print('--- Embeddings ---')\n",
    "for c, s in retrieve_embeddings(query, k=3):\n",
    "    print(_format_hit(c, s))\n",
    "\n",
    "print('--- Hybrid (alpha=0.5) ---')\n",
    "for c, s in retrieve_hybrid(query, k=3, alpha=0.5):\n",
    "    print(_format_hit(c, s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try some of the following:\n",
    "- A query using synonyms (e.g., *\"master in artificial intelligence\"* vs *\"MSc Data Science\"*).\n",
    "- A query mentioning a specific place (e.g., *\"Where can I study quietly in Marseille?\"*).\n",
    "- Change `alpha` in `retrieve_hybrid` to emphasise either BM25 (lexical) or embeddings (semantic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BM25 ===\n",
      "[score=2.026] Data Science track – overview → The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
      "It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
      "de...\n",
      "[score=0.535] Structure and learning sites → The DS track is organised over two years (M1 and M2). In the first year, students consolidate\n",
      "their background in analysis, probability, statistics and programming, while discov...\n",
      "[score=0.390] Structure and learning sites → Teaching takes place mainly on the Saint-Charles campus in Marseille, with some activities on\n",
      "other science sites. Courses combine lectures, tutorials and computer labs using Py...\n",
      "\n",
      "=== Embeddings ===\n",
      "[score=0.471] Structure and learning sites → In the second year, the focus moves to advanced statistical learning, high-dimensional data,\n",
      "optimisation for machine learning, and applications such as signal and image process...\n",
      "[score=0.379] Data Science track – overview → The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
      "and industrial partners. A significant part of the training is project-based, ...\n",
      "[score=0.316] Data Science track – overview → Students take courses in probability, optimisation, statistical modelling, signal and image\n",
      "processing, databases, machine learning and programming. The goal is to be able to de...\n",
      "\n",
      "=== Hybrid (alpha=0.5) ===\n",
      "[score=0.612] Data Science track – overview → The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
      "It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
      "de...\n",
      "[score=0.583] Structure and learning sites → In the second year, the focus moves to advanced statistical learning, high-dimensional data,\n",
      "optimisation for machine learning, and applications such as signal and image process...\n",
      "[score=0.415] Data Science track – overview → The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
      "and industrial partners. A significant part of the training is project-based, ...\n"
     ]
    }
   ],
   "source": [
    "query = \"master in artificial intelligence\"\n",
    "\n",
    "print(\"=== BM25 ===\")\n",
    "for c, s in retrieve_bm25(query, k=3):\n",
    "    print(_format_hit(c, s))\n",
    "\n",
    "print(\"\\n=== Embeddings ===\")\n",
    "for c, s in retrieve_embeddings(query, k=3):\n",
    "    print(_format_hit(c, s))\n",
    "\n",
    "print(\"\\n=== Hybrid (alpha=0.5) ===\")\n",
    "for c, s in retrieve_hybrid(query, k=3, alpha=0.5):\n",
    "    print(_format_hit(c, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BM25 ===\n",
      "[score=0.535] Structure and learning sites → The DS track is organised over two years (M1 and M2). In the first year, students consolidate\n",
      "their background in analysis, probability, statistics and programming, while discov...\n",
      "[score=0.390] Structure and learning sites → Teaching takes place mainly on the Saint-Charles campus in Marseille, with some activities on\n",
      "other science sites. Courses combine lectures, tutorials and computer labs using Py...\n",
      "[score=0.385] Careers and skills → Graduates of the DS track typically work as data scientists or data engineers, but also as\n",
      "statisticians or machine learning engineers in sectors such as digital services, indus...\n",
      "\n",
      "=== Embeddings ===\n",
      "[score=0.613] Structure and learning sites → Teaching takes place mainly on the Saint-Charles campus in Marseille, with some activities on\n",
      "other science sites. Courses combine lectures, tutorials and computer labs using Py...\n",
      "[score=0.472] Data Science track – overview → The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
      "and industrial partners. A significant part of the training is project-based, ...\n",
      "[score=0.189] Structure and learning sites → The DS track is organised over two years (M1 and M2). In the first year, students consolidate\n",
      "their background in analysis, probability, statistics and programming, while discov...\n",
      "\n",
      "=== Hybrid (alpha=0.5) ===\n",
      "[score=0.864] Structure and learning sites → Teaching takes place mainly on the Saint-Charles campus in Marseille, with some activities on\n",
      "other science sites. Courses combine lectures, tutorials and computer labs using Py...\n",
      "[score=0.712] Data Science track – overview → The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
      "and industrial partners. A significant part of the training is project-based, ...\n",
      "[score=0.624] Structure and learning sites → The DS track is organised over two years (M1 and M2). In the first year, students consolidate\n",
      "their background in analysis, probability, statistics and programming, while discov...\n"
     ]
    }
   ],
   "source": [
    "query = \"Where can I study quietly in Marseille?\"\n",
    "\n",
    "print(\"=== BM25 ===\")\n",
    "for c, s in retrieve_bm25(query, k=3):\n",
    "    print(_format_hit(c, s))\n",
    "\n",
    "print(\"\\n=== Embeddings ===\")\n",
    "for c, s in retrieve_embeddings(query, k=3):\n",
    "    print(_format_hit(c, s))\n",
    "\n",
    "print(\"\\n=== Hybrid (alpha=0.5) ===\")\n",
    "for c, s in retrieve_hybrid(query, k=3, alpha=0.5):\n",
    "    print(_format_hit(c, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hybrid α=0.0 ===\n",
      "[score=1.000] Structure and learning sites → In the second year, the focus moves to advanced statistical learning, high-dimensional data,\n",
      "optimisation for machine learning, and applications such as signal and image process...\n",
      "[score=0.315] Data Science track – overview → The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
      "It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
      "de...\n",
      "[score=0.302] Structure and learning sites → The DS track is organised over two years (M1 and M2). In the first year, students consolidate\n",
      "their background in analysis, probability, statistics and programming, while discov...\n",
      "\n",
      "=== Hybrid α=0.5 ===\n",
      "[score=0.657] Data Science track – overview → The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
      "It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
      "de...\n",
      "[score=0.614] Data Science track – overview → The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
      "and industrial partners. A significant part of the training is project-based, ...\n",
      "[score=0.556] Data Science track – overview → Students take courses in probability, optimisation, statistical modelling, signal and image\n",
      "processing, databases, machine learning and programming. The goal is to be able to de...\n",
      "\n",
      "=== Hybrid α=1.0 ===\n",
      "[score=1.000] Data Science track – overview → The Data Science (DS) track is part of the Master MAS at Aix-Marseille Université.\n",
      "It is a multidisciplinary programme in applied mathematics, statistics and computer science\n",
      "de...\n",
      "[score=0.936] Data Science track – overview → The programme is taught in Marseille with close links to local research laboratories (I2M and LIS)\n",
      "and industrial partners. A significant part of the training is project-based, ...\n",
      "[score=0.921] Data Science track – overview → Students take courses in probability, optimisation, statistical modelling, signal and image\n",
      "processing, databases, machine learning and programming. The goal is to be able to de...\n"
     ]
    }
   ],
   "source": [
    "query = \"Where are classes held for the data science programme?\"\n",
    "\n",
    "for alpha in [0.0, 0.5, 1.0]:\n",
    "    print(f\"\\n=== Hybrid α={alpha} ===\")\n",
    "    for c, s in retrieve_hybrid(query, k=3, alpha=alpha):\n",
    "        print(_format_hit(c, s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) From retrieval to augmented prompts\n",
    "\n",
    "We now connect the retriever to the chat model.\n",
    "\n",
    "We will:\n",
    "- Ask a question **without RAG** (no context),\n",
    "- Ask the same question **with RAG** (top chunks added to the prompt),\n",
    "- Compare the answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(chosen_chunks: List[Dict[str, str]]) -> str:\n",
    "    # Build context string from chosen chunks\n",
    "    parts = []\n",
    "    for i, c in enumerate(chosen_chunks, start=1):\n",
    "        parts.append(f\"\"\"[{i}] {c['title']} (campus={c['campus']}, program={c['program']})\n",
    "{c['text']}\"\"\")\n",
    "    return '\\n\\n'.join(parts)\n",
    "\n",
    "\n",
    "def answer_without_rag(question: str) -> str:\n",
    "    prompt = textwrap.dedent(f''' \n",
    "    QUESTION:\n",
    "    {question}\n",
    "    ''').strip()\n",
    "    resp = model_general.generate_content(question, generation_config=GEN_CONFIG)\n",
    "    return resp.text or ''\n",
    "\n",
    "\n",
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    k: int = 4,\n",
    "    alpha: float = 0.5,\n",
    "    campus: str | None = None,\n",
    "    program: str | None = None,\n",
    ") -> Tuple[str, List[Dict[str, str]]]:\n",
    "    # Step 1: hybrid retrieval\n",
    "    hits = retrieve_hybrid(question, k=10, alpha=alpha)\n",
    "\n",
    "    # Step 2: metadata-based refinement (final filter, as in the lecture)\n",
    "    if campus or program:\n",
    "        filtered = []\n",
    "        for chunk, score in hits:\n",
    "            if campus is not None and chunk['campus'] != campus:\n",
    "                continue\n",
    "            if program is not None and chunk['program'] != program:\n",
    "                continue\n",
    "            filtered.append((chunk, score))\n",
    "        hits = filtered or hits  # fall back if filter is too strict\n",
    "\n",
    "    chosen_chunks = [c for c, _ in hits[:k]]\n",
    "    context = build_context(chosen_chunks)\n",
    "\n",
    "    prompt = textwrap.dedent(f''' \n",
    "        CONTEXT:\n",
    "        {context}\n",
    "\n",
    "        QUESTION:\n",
    "        {question}\n",
    "    ''').strip()\n",
    "\n",
    "    resp = model_rag.generate_content(prompt, generation_config=GEN_CONFIG)\n",
    "    return resp.text or '', chosen_chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: lectures in Marseille\n",
    "\n",
    "We reuse our earlier query and compare:\n",
    "- the answer without RAG,\n",
    "- the answer with RAG (hybrid + metadata refinement).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Without RAG ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763371807.207111   10773 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science lectures are typically held at Aix-Marseille Université (AMU), primarily on the **Luminy campus** and sometimes the **Saint-Charles campus**.\n",
      "--- With RAG (hybrid + metadata filter) ---\n",
      "Data science lectures are mainly held on the Saint-Charles campus in Marseille.\n",
      "SOURCES: [1]\n",
      "[Context chunks used:]\n",
      "- prog_ds_structure_p2 from Structure and learning sites\n",
      "- prog_ds_overview_p2 from Data Science track – overview\n",
      "- prog_ds_overview_p0 from Data Science track – overview\n",
      "- prog_ds_structure_p1 from Structure and learning sites\n"
     ]
    }
   ],
   "source": [
    "q = 'Where are the data science lectures usually held in Marseille?'\n",
    "\n",
    "print('--- Without RAG ---')\n",
    "print(answer_without_rag(q))\n",
    "\n",
    "print('--- With RAG (hybrid + metadata filter) ---')\n",
    "answer, used_chunks = answer_with_rag(q, campus='Marseille', program='Data Science')\n",
    "print(answer)\n",
    "\n",
    "print('[Context chunks used:]')\n",
    "for c in used_chunks:\n",
    "    print('-', c['chunk_id'], 'from', c['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Try questions where the answer **is** in the corpus and where it is **not**.\n",
    "- Does the RAG answer correctly admit when it does not know?\n",
    "- Vary `k` (number of chunks) and observe when the answer becomes better or worse.\n",
    "- Add a new document to `documents` (e.g., another campus or a new study spot) and re-run the indexing cell. How does it change the retrieved chunks and answers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Without RAG ===\n",
      "At the Luminy campus of Aix-Marseille University. \n",
      "\n",
      "=== With RAG ===\n",
      "Data science lectures are usually held mainly on the Saint-Charles campus in Marseille, with some activities on other science sites.\n",
      "SOURCES: [1] \n",
      "\n",
      "[Chunks used:]\n",
      "- prog_ds_structure_p2\n",
      "- prog_ds_overview_p0\n",
      "- prog_ds_overview_p2\n",
      "- prog_ds_structure_p0\n"
     ]
    }
   ],
   "source": [
    "q = \"Where are data science lectures usually held?\"\n",
    "\n",
    "print(\"=== Without RAG ===\")\n",
    "print(answer_without_rag(q), \"\\n\")\n",
    "\n",
    "print(\"=== With RAG ===\")\n",
    "answer, used = answer_with_rag(q, campus=\"Marseille\", program=\"Data Science\")\n",
    "print(answer, \"\\n\")\n",
    "\n",
    "print(\"[Chunks used:]\")\n",
    "for c in used:\n",
    "    print(\"-\", c[\"chunk_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Without RAG ===\n",
      "No, the standard Data Science programme does not typically include a course on quantum computing. \n",
      "\n",
      "=== With RAG ===\n",
      "I do not know.\n",
      "SOURCES: [] \n",
      "\n",
      "[Chunks used:]\n",
      "- prog_ds_overview_p0\n",
      "- prog_ds_overview_p2\n",
      "- prog_ds_structure_p0\n",
      "- prog_ds_careers_p0\n"
     ]
    }
   ],
   "source": [
    "q = \"Does the DS programme include a course on quantum computing?\"\n",
    "\n",
    "print(\"=== Without RAG ===\")\n",
    "print(answer_without_rag(q), \"\\n\")\n",
    "\n",
    "print(\"=== With RAG ===\")\n",
    "answer, used = answer_with_rag(q, campus=\"Marseille\", program=\"Data Science\")\n",
    "print(answer, \"\\n\")\n",
    "\n",
    "print(\"[Chunks used:]\")\n",
    "for c in used:\n",
    "    print(\"-\", c[\"chunk_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== With RAG (k=1) ===\n",
      "I do not know what the DS programme teaches in the second year based on the provided context. The context only describes the curriculum for the first year (M1).\n",
      "SOURCES: [1]\n",
      "Chunks: ['prog_ds_structure_p0']\n",
      "\n",
      "=== With RAG (k=2) ===\n",
      "I do not know.\n",
      "SOURCES: []\n",
      "Chunks: ['prog_ds_structure_p0', 'prog_ds_overview_p0']\n",
      "\n",
      "=== With RAG (k=4) ===\n",
      "In the second year of the DS program, the focus is on advanced statistical learning, high-dimensional data, optimisation for machine learning, and applications such as signal and image processing. Some modules are shared with other tracks of the MAS master, which helps maintain a strong mathematical core.\n",
      "SOURCES: [4]\n",
      "Chunks: ['prog_ds_structure_p0', 'prog_ds_overview_p0', 'prog_ds_careers_p0', 'prog_ds_structure_p1']\n",
      "\n",
      "=== With RAG (k=6) ===\n",
      "In the second year of the DS programme, the focus is on advanced statistical learning, high-dimensional data, optimisation for machine learning, and applications such as signal and image processing.\n",
      "SOURCES: [4]\n",
      "Chunks: ['prog_ds_structure_p0', 'prog_ds_overview_p0', 'prog_ds_careers_p0', 'prog_ds_structure_p1', 'prog_ds_overview_p2', 'prog_ds_careers_p1']\n"
     ]
    }
   ],
   "source": [
    "q = \"What does the DS programme teach in the second year?\"\n",
    "\n",
    "for k in [1, 2, 4, 6]:\n",
    "    print(f\"\\n=== With RAG (k={k}) ===\")\n",
    "    answer, used = answer_with_rag(q, k=k, campus=\"Marseille\", program=\"Data Science\")\n",
    "    print(answer)\n",
    "    print(\"Chunks:\", [c['chunk_id'] for c in used])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.append({\n",
    "    'id': 'marseille_study_spots',\n",
    "    'title': 'Study spots in Marseille',\n",
    "    'campus': 'Marseille',\n",
    "    'program': 'General',\n",
    "    'text': \"\"\"\\\n",
    "        Marseille offers several quiet places to study.\n",
    "        Popular choices include the Saint-Charles university library,\n",
    "        the Alcazar public library near the Vieux-Port,\n",
    "        and the campus learning centre with group-study rooms.\n",
    "    \"\"\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = make_chunks(documents)\n",
    "\n",
    "corpus_texts = [c['text'] for c in chunks]\n",
    "tokenized_corpus = [t.lower().split() for t in corpus_texts]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "emb_matrix = embedder.encode(corpus_texts, convert_to_numpy=True, normalize_embeddings=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marseille offers several quiet places to study, including the Saint-Charles university library, the Alcazar public library near the Vieux-Port, and the campus learning centre which has group-study rooms.\n",
      "SOURCES: [4]\n",
      "Chunks: ['prog_ds_structure_p2', 'prog_ds_overview_p2', 'prog_ds_structure_p0', 'marseille_study_spots_p0']\n"
     ]
    }
   ],
   "source": [
    "q = \"Where can I study quietly in Marseille?\"\n",
    "\n",
    "answer, used = answer_with_rag(q, k=4)\n",
    "\n",
    "print(answer)\n",
    "print(\"Chunks:\", [c['chunk_id'] for c in used])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) (Optional) Evaluate retrieval with precision and recall\n",
    "\n",
    "For a real project, you would:\n",
    "- create a small set of labelled queries with known relevant chunks,\n",
    "- compute **precision** and **recall** for your retriever,\n",
    "- tune parameters (e.g., `alpha`, `k`) to get high recall while keeping prompts small.\n",
    "\n",
    "You can sketch your own mini-evaluation below by defining a few queries and lists of relevant `chunk_id`s. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: small manual evaluation scaffold\n",
    "# Example structure; fill in your own queries and relevant chunks.\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        'query': 'Where does the Data Science track take place?',\n",
    "        'relevant_chunk_ids': ['prog_ds_structure_p2', 'prog_ds_overview_p2'],\n",
    "    },\n",
    "    {\n",
    "        'query': 'What kinds of jobs can graduates of the Data Science track expect?',\n",
    "        'relevant_chunk_ids': ['prog_ds_careers_p0'],\n",
    "    },\n",
    "]\n",
    "\n",
    "alpha = 0.5\n",
    "k = 4\n",
    "\n",
    "for ex in examples:\n",
    "    hits = retrieve_hybrid(ex['query'], k=k, alpha=alpha)\n",
    "    retrieved_ids = [c['chunk_id'] for c, _ in hits]\n",
    "\n",
    "    tp = len(set(retrieved_ids) & set(ex['relevant_chunk_ids']))\n",
    "    fp = len(set(retrieved_ids) - set(ex['relevant_chunk_ids']))\n",
    "    fn = len(set(ex['relevant_chunk_ids']) - set(retrieved_ids))\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "\n",
    "    print('\\nQuery:', ex['query'])\n",
    "    print('Retrieved:', retrieved_ids)\n",
    "    print('Relevant:', ex['relevant_chunk_ids'])\n",
    "    print(f'Precision={precision:.2f}, Recall={recall:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
